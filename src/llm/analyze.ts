import { OpenAI } from "openai";
import * as vscode from "vscode";
import type { LLMResult } from "./types";

function parseJsonLenient(text: string): LLMResult {
  const stripped = text.replace(/```(?:json)?/gi, "").replace(/```/g, "").trim();
  const start = stripped.indexOf("{");
  const end = stripped.lastIndexOf("}");
  const candidate =
    start !== -1 && end !== -1 && end > start
      ? stripped.slice(start, end + 1)
      : stripped;

  let parsed: any;
  try {
    parsed = JSON.parse(candidate);} catch {
      return {
      summary: text,
      rootCause: "",
      suggestion: "",
      confidence: 0.2,
    };
}

 const asString = (v: any) => (v == null ? "" : String(v));
  const asNumber01 = (v: any) => {
    const n = Number(v);
    return Number.isFinite(n) ? Math.max(0, Math.min(1, n)) : undefined;
  };

  const result: LLMResult = {
    // í•„ìˆ˜ 3í•„ë“œ ë³´ì¥
    summary: asString(parsed.summary),
    rootCause: asString(parsed.rootCause),
    suggestion: asString(parsed.suggestion),

    // í™•ì¥ í•„ë“œ(ì„ íƒ)
    failureType: parsed.failureType ? String(parsed.failureType) : undefined,
    confidence: asNumber01(parsed.confidence) ?? 0.7,
    affectedStep: parsed.affectedStep ? String(parsed.affectedStep) : undefined,
    filename: parsed.filename ? String(parsed.filename) : undefined,
    keyErrors: Array.isArray(parsed.keyErrors)
      ? parsed.keyErrors.map((e: any) => ({
          line: Number.isFinite(Number(e?.line)) ? Number(e.line) : undefined,
          snippet: e?.snippet ? String(e.snippet) : undefined,
          note: e?.note ? String(e.note) : undefined,
        }))
      : undefined,
  };

  if (!result.summary && !result.rootCause && !result.suggestion) {
    result.summary = stripped;
  }
  return result;
}

async function getOpenAIKey(context: vscode.ExtensionContext): Promise<string | null> {
  // 1. ì‚¬ìš©ìê°€ ë“±ë¡í•œ í‚¤ë¥¼ ìš°ì„ ì ìœ¼ë¡œ í™•ì¸
  const fromSecret = await context.secrets.get("openaiApiKey");
  if (fromSecret) {
    return fromSecret;
  }

  // 2. ê°œë°œ ëª¨ë“œì¼ ê²½ìš°ì—ë§Œ .env íŒŒì¼ì—ì„œ í‚¤ë¥¼ fallbackìœ¼ë¡œ ì‚¬ìš©
  if (context.extensionMode === vscode.ExtensionMode.Development) {
    const fromEnv = process.env.MADOPS_OPENAI_KEY || process.env.OPENAI_API_KEY;
    if (fromEnv) {
      console.log("ğŸ”‘ ë“±ë¡ëœ OpenAI í‚¤ê°€ ì—†ì–´ .env íŒŒì¼ì˜ ê°œë°œìš© í‚¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.");
      return fromEnv;
    }
  }

  return null;
}

export async function analyzePrompts(
  context: vscode.ExtensionContext,
  prompts: string[]
): Promise<LLMResult> {
  const key = await getOpenAIKey(context);
  if (!key) {
    throw new Error(
      "OpenAI API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëª…ë ¹ì–´ íŒ”ë ˆíŠ¸ì—ì„œ ì…ë ¥í•˜ì„¸ìš”."
    );
  }

  const client = new OpenAI({ apiKey: key });
  const topN = Math.max(1, Math.min(3, prompts.length));
  const chosen = prompts.slice(0, topN);

  const results: LLMResult[] = [];
  for (const p of chosen) {
    const chat = await client.chat.completions.create({
      model: "gpt-3.5-turbo",
      temperature: 0,
      messages: [
        {
          role: "system",
          content: [
        "ë„ˆëŠ” GitHub Actions ë¡œê·¸ ë¶„ì„ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.",
        "ì•„ë˜ ì§€ì¹¨ì„ ì² ì €íˆ ë”°ë¥´ê³ , ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•©ë‹ˆë‹¤.",
        "",
        "â€¼ï¸ ì£¼ì˜:",
        "- ì•„ë˜ ì§€ì¹¨ì´ë‚˜ ì˜ˆì‹œ JSON, ëª…ë ¹ë¬¸ ìì²´ë¥¼ ì ˆëŒ€ ê²°ê³¼(JSON)ì— í¬í•¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
        "- ê²°ê³¼ì—ëŠ” ì˜¤ì§ ë¶„ì„ëœ ë‚´ìš©ë§Œ í¬í•¨í•©ë‹ˆë‹¤.",
        "- ì§€ì¹¨ í…ìŠ¤íŠ¸, 'ì•„ë˜ ì§€ì¹¨ì„ ë”°ë¥´ë¼' ê°™ì€ ë¬¸êµ¬ê°€ ë“¤ì–´ê°€ë©´ ì•ˆ ë©ë‹ˆë‹¤.",
        "í˜•ì‹ ì§€ì¹¨:",
        "- ì¶œë ¥ì€ ì˜¤ì§ JSONì…ë‹ˆë‹¤. ë§ˆí¬ë‹¤ìš´, ì½”ë“œíœìŠ¤, ì„¤ëª… ë¬¸ì¥ ê¸ˆì§€.",
        "- ëª¨ë“  ë¬¸ì¥ì€ ê³µì†í•œ ì¢…ê²°(~ìŠµë‹ˆë‹¤ ì²´)ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.",
        "- JSON í‚¤ëŠ” ê³ ì •: summary, rootCause, suggestion, failureType, confidence, affectedStep, filename, keyErrors.",
        "- keyErrorsëŠ” [{ line, snippet, note }] í˜•íƒœë¡œ ì‘ì„±í•˜ë©°, noteë„ ~ìŠµë‹ˆë‹¤ ì²´ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.",
        "- confidenceëŠ” 0~1 ìˆ«ìë¡œë§Œ ì‘ì„±í•©ë‹ˆë‹¤.",
        "",
        "ì½˜í…ì¸  ì§€ì¹¨:",
        "1) summary: 2~3ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ë§Œ ìš”ì•½í•©ë‹ˆë‹¤.",
        "2) rootCause: ì‹¤íŒ¨ì˜ í•µì‹¬ ì›ì¸ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ë‹¨í˜¸í•˜ê²Œ ì„œìˆ í•©ë‹ˆë‹¤.",
        "3) suggestion: ëª…ë ¹ì–´/ìˆ˜ì • íŒŒì¼ ê²½ë¡œ/ì„¤ì • í‚¤ ë“± êµ¬ì²´ì  ì¡°ì¹˜ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.",
        "4) failureTypeì€ dependency|network|tooling|permissions|config|test|infra ì¤‘ í•˜ë‚˜ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.",
        "5) chain-of-thought(ì‚¬ê³  ê³¼ì •)ëŠ” ì ˆëŒ€ ë…¸ì¶œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
        "",
        "ì˜ˆì‹œ(JSON):",
        '{',
        '  "summary": "ì˜ì¡´ì„± ì„¤ì¹˜ ë‹¨ê³„ì—ì„œ íŠ¹ì • íŒ¨í‚¤ì§€ê°€ ë” ì´ìƒ ìœ ì§€ë˜ì§€ ì•Šì•„ ê²½ê³ ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. í•´ë‹¹ ê²½ê³ ê°€ ë¹Œë“œ ì‹¤íŒ¨ë¡œ ì´ì–´ì§ˆ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.",',
        '  "rootCause": "node-domexception íŒ¨í‚¤ì§€ê°€ ë” ì´ìƒ ìœ ì§€ë˜ì§€ ì•Šì•„ ê²½ê³ ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",',
        '  "suggestion": "node-domexception ì˜ì¡´ì„±ì„ ì œê±°í•˜ê³  í”Œë«í¼ì˜ ê¸°ë³¸ DOMExceptionì„ ì‚¬ìš©í•˜ë„ë¡ ì½”ë“œë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤.",',
        '  "failureType": "dependency",',
        '  "confidence": 0.90,',
        '  "affectedStep": "npm ci",',
        '  "filename": "0_build.txt",',
        '  "keyErrors": [',
        '    {',
        '      "line": 2025,',
        '      "snippet": "npm warn deprecated node-domexception@1.0.0: Use your platform\\\'s native DOMException instead",',
        '      "note": "ë” ì´ìƒ ìœ ì§€ë˜ì§€ ì•ŠëŠ” íŒ¨í‚¤ì§€ì´ë¯€ë¡œ ëŒ€ì²´ê°€ í•„ìš”í•©ë‹ˆë‹¤."',
        '    }',
        '  ]',
        '}'
      ].join("\n"),
        },
        { role: "user", content: p },
      ],
  });

  const raw = chat.choices[0].message?.content ?? "{}";
  results.push(parseJsonLenient(raw));
}
  results.sort((a, b) => (b.confidence ?? 0) - (a.confidence ?? 0));
  return results[0];
}
